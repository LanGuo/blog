## word2vec

Word2vec is an unsupervised machine learning model which is able to capture semantic information from the text it is trained on.  The model is based on neural networks.  Several large organizations like Google and Facebook have trained word embeddings (the result of word2vec) on large corpora and shared them for others to use.

The key algorithmic ideas involved in word2vec is the continuous bag of words model (CBOW).  In this episode, Kyle uses excerpts from the 1983 cinematic masterpiece War Games, and challenges Linhda to guess a word Kyle leaves out of the transcript.  This is similar to how word2vec is trained.  It trains a neural network to predict a hidden word based on the words that appear before and after the missing location.


## Related Links

* [Original paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf).
* [Word2Vec visualizer](https://github.com/dominiek/word2vec-explorer)

