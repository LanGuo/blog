## Colossus: The Forbin Project

This 1970s film from Universal Pictures, based upon the 1966 science fiction novel Colossus, by Dennis Feltham Jones, is required watching in the genre of artificial intelligence movies.  It's the story of what happens when a military supercomputer comes on line and is given control of important systems.

Seeing as how this film is now 47 years old, we consider it fair game to include a few spoilers in this post, however, the intent is to not ruin the typical film watching experience for readers that intend to view it later.

In a nutshell, Colossus is asked to find a way to eliminate all the ills of the world: famine, illness, war, etc.  As will come as no surprise, the machine's solution to the problem is to take over control of the world and maintain strict order.

This film was not the first work of fiction to be made about a powerful machine arriving at this conclusion.  I'm not sure a true origin could be defined, as this idea is seeminly rooted in much older mythology.

In 1902, W. W. Jacobs published "The Monkey's Paw", a short story of a magic charm.  This charmed paw granted wishes, but in granting these wishes, often selects a solution which carries with it consequences so bad that the reward is insignificant.  For example, wishing for money which arrives in the form an inheritance from a close relative who died pre-maturely and unexpectedly.

The "wishing" aspect of this tale is surely inspired by earlier tales of wish granting djinn trapped in magic lamps.  Thus, I find these sorts of movies to be less about artificial intelligence, and more about a modernization of the "be careful what you wish for" genre.

I've never liked this genre.  I consistently find myself frustrated by the protagonists seeming unwillingness to put in the most basic effort to structuring a well specified wish.  Surely with the aid of a few attorneys, a robust wish could be written which yields a benefit and no undo consequences in the delivery of the wish.  Why couldn't the main character add enough conditions to the wish to reduce the degrees of freedom alloted the grantor?

In some sense, this is how most people seem to response to concerns about malevolent AI.  A growing body of reports are being written about safely interruptible agents and other aspects of "AI safety."  I do agree that these are worthwhile explorations.  If an when machines exist which can be described as "artificial general intelligence", they'll still be machines.  And as every engineer knows, safety is a major concern in the design of any system which can effect people's lives.

Let's assume a computer like the one staring in "Collossus: The Forbin Project" has been created and has been given the broad access the machine in the film had.  Next, this machine is tasked with finding and executing a solution to minimize war.  How likely is it that this machine would arrive at the same solution - human domination?

Admittedly, it isn't entirely out of the question.  Sometimes a teacher needs to step in to manage the more dangerous school-yard antics that aren't able to work themselves out naturally.  Perhaps a machine would see itself in a similar role to the teacher, and therefore having the same (non-malevalent) intent.

So would such a machine see us as children?  We don't know.  No one does.  Yet.  Much ado has been made about how much more "advanced" intelligent machines would be than humans.  How much more advanced are humans compared to dolphins?  Evolution has no direction.  Each species is highly optimized to survive in a distinct content, and has traits befitting of that struggle.  Dolphins win in any swimming race.  Superiority requires context.

It's been hypothesized that artificially intelligent painting algorithms will eventually be able to produce masterpiece paintings at a controlled and predictable rate, perhaps 1 per second.  But how many true masterpieces are still masterpieces when existing in a set of other masterpieces so large, no human can view them all in a lifetime.

Assuming an artificial general intelligence didn't simply ignore us, they'd have to be willing and able to interact with us on terms that are compatible with our biology.  Though such a machine might be very different from us, it would still be interacting with us, motivated by it's own objectives and self-interest, yet intelligent to recognize that we are also self-interested agents with whom it can gain benefit through int eraction as well.

A machine intelligence capable of plotting to dominate humanity is surely capable of learning a little game theory.  As such, it would likely recognize that a collaborative solution is almost certainly preferential to all parties than an authoritarian solution.  There's room for error here in three ways.  First, as humans exhibit, the machine could exhibit irrational preferences and beliefs.  These could prevent it from making optimal decisions.  Second, it could have access to incorrect data, and have therefore drawn incorrect conclusions.  Yet, in the planning stages of world domination, you think you'd want to check your work for errors and that if you had some faulty information, there would be consistency issues in your plan that hint at this.  Third, the machine could have such an extremely superior position in any conflict that humans pose no credible threat.

Many science fiction authors seem to elect the third option, most likely, because it's the only one that leads to novel and interesting conflict for the story.

A machine capable of world domination must surely be able to reason probabilistically.  Any planning it does would consider a variety of tactics and weigh each both by how much they prefer the likely outcome of the tactic with how likely it is to succeed.  If the machine is indeed coldly logical, then it will select the strategy which maximizes expected future reward.  A collaborative approach carries less risks.

An adversarial machine wanting confidence in it's own ability to dominate the human race would want to dedicate a large amount of it's processing power to simulating what oppressed human beings might do to resist.  Even if this machine is somehow more "advanced" than we are, we're still large meat bags that will take a lot of computational power to simulate effectively.  Thus, it seems a super advanced dictatorial artificial intelligence would spend a lot of time worrying about the variety of ways humans might try to unplug it.

Whether game theory, AI safety engineering, or some other reason gives you hope that we're not approaching a time when AI enslaves humanity, "Colossus: The Forbin Project" is an enjoyable movie with very few if any cringe-worthy moments of implausibility or poorly written technobabble.

Several years ago there were rumors of a remake involving Will Smith.  However, news on this front has been quiet for some time.