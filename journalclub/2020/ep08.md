# Journal Club, episode 8

Kyle: AlphaFold

George: Tree SHAP & Student alcohol consumption blog

Lan leads the discussion of the paper [Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/abs/1905.02175) by Ilyas and colleagues. This papers proposes a new perspective on adversarial susceptibility of machine learning models by teasing apart the 'robust' and the 'non-robust' features in a dataset. The authors summarizes the key take away message as "Adversarial vulnerability is a direct result of the models’ sensitivity to well-generalizing, ‘non-robust’ features in the data." 
